{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvp_LYvFlaJ2"
      },
      "source": [
        "\n",
        "\n",
        "# ML Study Jam Exercise 3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Kaggle Library"
      ],
      "metadata": {
        "id": "yKN_0C6EhHiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install kaggle libary\n",
        "%pip install -q kaggle"
      ],
      "metadata": {
        "id": "0rXctsWkic3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# upload Kaggle API Credentials\n",
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "3JJPS7enic3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add kaggle API credentials to root\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "DsVM5RYjic3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new folder to save dataset\n",
        "! mkdir ./kaggleDataset\n",
        "\n",
        "# set Directory as current directory\n",
        "%cd ./kaggleDataset"
      ],
      "metadata": {
        "id": "hBcdw1gkic3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list kaggle datasets\n",
        "! kaggle datasets list"
      ],
      "metadata": {
        "id": "jfq9hAhNic3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computer Vision"
      ],
      "metadata": {
        "id": "JPFV3E0IGgUl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding CNN"
      ],
      "metadata": {
        "id": "6Jo6r-jaGkfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "from  shutil import copyfile\n",
        "import random"
      ],
      "metadata": {
        "id": "2gm6Mjd4x-ER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create new dir for dataset\n",
        "! mkdir ./dogs-vs-cats\n",
        "\n",
        "# set Directory as current directory\n",
        "%cd ./dogs-vs-cats"
      ],
      "metadata": {
        "id": "z-2FL1h4qLIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download the dataset\n",
        "!kaggle datasets download -d biaiscience/dogs-vs-cats"
      ],
      "metadata": {
        "id": "7fQPRSWai8bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete path to storage location of the .zip file of data\n",
        "zip_path = '/content/kaggleDataset/dogs-vs-cats/dogs-vs-cats.zip'\n",
        "# Check current directory (be sure you're in the directory where Colab operates: '/content')\n",
        "os.getcwd()\n",
        "# Copy the .zip file into the present directory\n",
        "!cp '{zip_path}' .\n",
        "# Unzip quietly\n",
        "!unzip -q 'dogs-vs-cats.zip'\n",
        "# View the unzipped contents in the virtual machine\n",
        "os.listdir()"
      ],
      "metadata": {
        "id": "mLQggAmkjFw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up file paths\n",
        "TRAIN_PATH='/content/kaggleDataset/dogs-vs-cats/train/train'\n",
        "TEST_PATH='/content/kaggleDataset/dogs-vs-cats/test/test'"
      ],
      "metadata": {
        "id": "7pR7Q21SqpDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract class label from file name\n",
        "def label_img(img):\n",
        "    word_label = img.split('.')[-3]\n",
        "    if word_label == 'cat': return 'cat'\n",
        "    elif word_label == 'dog': return 'dog'\n",
        "\n",
        "# Prepare dataframes\n",
        "train_images = os.listdir(TRAIN_PATH)\n",
        "\n",
        "train_labels = [label_img(img) for img in train_images]\n",
        "\n",
        "train_df = pd.DataFrame({\n",
        "    'filename': train_images,\n",
        "    'category': train_labels\n",
        "})\n",
        "\n",
        "# Shuffle the dataframe and split into train and validation\n",
        "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
        "validation_df = train_df.iloc[:250]  # first 250 for validation\n",
        "train_df = train_df.iloc[250:].reset_index(drop=True)  # rest for training"
      ],
      "metadata": {
        "id": "igvvVu_Ly92f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.iloc[:1000].reset_index(drop=True) # keep first 1000 images only\n",
        "train_df"
      ],
      "metadata": {
        "id": "Owyg7YTE-pHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1./255,\n",
        "                                           rotation_range=45,\n",
        "                                           width_shift_range=.15,\n",
        "                                           height_shift_range=.15,\n",
        "                                           horizontal_flip=True,\n",
        "                                           zoom_range=0.3\n",
        "                                           ) # Generator for our training data"
      ],
      "metadata": {
        "id": "R0xY3PWlzyQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data"
      ],
      "metadata": {
        "id": "Wnz9jRwd0Ewt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_gen = train_image_generator.flow_from_dataframe(train_df,\n",
        "                                                           directory=TRAIN_PATH,\n",
        "                                                           x_col='filename',\n",
        "                                                           y_col='category',\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(150, 150),\n",
        "                                                           class_mode='binary',\n",
        "                                                           batch_size=256\n",
        "                                                           )\n",
        "val_data_gen = validation_image_generator.flow_from_dataframe(validation_df,\n",
        "                                                              directory=TRAIN_PATH,\n",
        "                                                              x_col='filename',\n",
        "                                                              y_col='category',\n",
        "                                                              shuffle=False,  # Keep data in same order as labels\n",
        "                                                              class_mode='binary',\n",
        "                                                              target_size=(150, 150),\n",
        "                                                              batch_size=256\n",
        "                                                              )"
      ],
      "metadata": {
        "id": "N0HPSZ5j0F7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "wZbPKfIc1rGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "metadata": {
        "id": "i1GDWsxV2yPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_training_images, sample_training_labels = next(train_data_gen)\n",
        "plotImages(sample_training_images[:5])"
      ],
      "metadata": {
        "id": "Kbq6LS9m3OfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "LT9kwbYgqbdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a simple CNN model\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(150, 150 ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.2),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "hyFJ3486m8IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print model details\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "yWfqf7lt9MvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "St3kbYVd9puY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "model.fit(train_data_gen, epochs=2, validation_data=val_data_gen, callbacks=[tensorboard_callback])"
      ],
      "metadata": {
        "id": "GEUnq243APYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "metadata": {
        "id": "jkuNbam8Shec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('cats_and_dogs_model.h5')"
      ],
      "metadata": {
        "id": "OkRcBniNdMES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotFilters(conv_filter):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(5,5))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( conv_filter, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "H7_ZHKlhB2d9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing the filters\n",
        "for layer in model.layers:\n",
        "    if 'conv' in layer.name:\n",
        "        weights, bias= layer.get_weights()\n",
        "        print(layer.name, weights.shape)\n",
        "         #normalize filter values between  0 and 1 for visualization\n",
        "        f_min, f_max = weights.min(), weights.max()\n",
        "        filters = (weights - f_min) / (f_max - f_min)\n",
        "        print(weights.shape[3])\n",
        "        filter_cnt=1\n",
        "        #plotting all the filters\n",
        "        for i in range(filters.shape[3]):\n",
        "            #get the filters\n",
        "            filt=filters[:,:,:, i]\n",
        "            #plotting ecah channel\n",
        "            for j in range(filters.shape[0]):\n",
        "                ax= plt.subplot(filters.shape[3], filters.shape[0], filter_cnt  )\n",
        "                ax.set_xticks([])\n",
        "                ax.set_yticks([])\n",
        "                plt.imshow(filt[:,:, j])\n",
        "                filter_cnt+=1\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "wSOjrKC3CWGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path='/content/kaggleDataset/dogs-vs-cats/train/train/cat.1341.jpg'\n",
        "# Let's define a new Model that will take an image as input, and will output\n",
        "# intermediate representations for all layers in the previous model after\n",
        "# the first.\n",
        "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
        "\n",
        "#visualization_model = Model(img_input, successive_outputs)\n",
        "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
        "\n",
        "img = load_img(img_path, target_size=(150, 150))  # this is a PIL image\n",
        "\n",
        "x   = img_to_array(img)                           # Numpy array with shape (150, 150, 3)\n",
        "x   = x.reshape((1,) + x.shape)                   # Numpy array with shape (1, 150, 150, 3)\n",
        "\n",
        "# Rescale by 1/255\n",
        "x /= 255.0\n",
        "\n",
        "# Let's run our image through our network, thus obtaining all\n",
        "# intermediate representations for this image.\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "\n",
        "# These are the names of the layers, so can have them as part of our plot\n",
        "layer_names = [layer.name for layer in model.layers]\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "# Now let's display our representations\n",
        "# -----------------------------------------------------------------------\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "  print(feature_map.shape)\n",
        "  if len(feature_map.shape) == 4:\n",
        "\n",
        "    #-------------------------------------------\n",
        "    # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
        "    #-------------------------------------------\n",
        "    n_features = feature_map.shape[-1]  # number of features in the feature map\n",
        "    size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n",
        "\n",
        "    # We will tile our images in this matrix\n",
        "    display_grid = np.zeros((size, size * n_features))\n",
        "\n",
        "    #-------------------------------------------------\n",
        "    # Postprocess the feature to be visually palatable\n",
        "    #-------------------------------------------------\n",
        "    for i in range(n_features):\n",
        "      x  = feature_map[0, :, :, i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std ()\n",
        "      x *=  64\n",
        "      x += 128\n",
        "      x  = np.clip(x, 0, 255).astype('uint8')\n",
        "      display_grid[:, i * size : (i + 1) * size] = x # Tile each filter into a horizontal grid\n",
        "\n",
        "    #-----------------\n",
        "    # Display the grid\n",
        "    #-----------------\n",
        "\n",
        "    scale = 20. / n_features\n",
        "    plt.figure( figsize=(scale * n_features, scale) )\n",
        "    plt.title ( layer_name )\n",
        "    plt.grid  ( False )\n",
        "    plt.imshow( display_grid, aspect='auto', cmap='viridis' )"
      ],
      "metadata": {
        "id": "vPYip02OCg67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer Learning"
      ],
      "metadata": {
        "id": "DdYPXjAeGoxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd # Data Frame processing\n",
        "import tensorflow as tf # Backend library for neural nets processing\n",
        "from keras import models, layers # Framework for neural nets creating\n",
        "import os, shutil # filesystem operations\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import random\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.applications import Xception\n",
        "from keras.applications import VGG19\n",
        "from keras.applications import ResNet50\n",
        "from keras.applications import MobileNet\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "7AKGF28UEhuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU checking\n",
        "device_names = tf.test.gpu_device_name()\n",
        "device_names"
      ],
      "metadata": {
        "id": "RbZg0FZ2ctkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up file paths\n",
        "TRAIN_PATH='/content/kaggleDataset/dogs-vs-cats/train/train'\n",
        "TEST_PATH='/content/kaggleDataset/dogs-vs-cats/test/test'"
      ],
      "metadata": {
        "id": "fF96IgkMTi7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_size = (150,150)\n",
        "batch_size = 256\n",
        "\n",
        "#Fetching train data and validation data and processing the data\n",
        "train_datagen = ImageDataGenerator(rescale = 1.00 / 255.0)\n",
        "val_datagen = ImageDataGenerator(rescale = 1.00 / 255.0)\n",
        "test_datagen = ImageDataGenerator(rescale = 1.00 / 255.0)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
        "                                                    directory=TRAIN_PATH,\n",
        "                                                    x_col='filename',\n",
        "                                                    y_col='category',\n",
        "                                                    shuffle=True,\n",
        "                                                    target_size=target_size,\n",
        "                                                    class_mode='binary',\n",
        "                                                    batch_size=batch_size\n",
        "                                                    )\n",
        "\n",
        "validation_generator = val_datagen.flow_from_dataframe(validation_df,\n",
        "                                                      directory=TRAIN_PATH,\n",
        "                                                      x_col='filename',\n",
        "                                                      y_col='category',\n",
        "                                                      shuffle=False,  # Keep data in same order as labels\n",
        "                                                      class_mode='binary',\n",
        "                                                      target_size=target_size,\n",
        "                                                      batch_size=batch_size\n",
        "                                                      )"
      ],
      "metadata": {
        "id": "7CZN5qvuTmdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _round(vec, threshold):\n",
        "    output = []\n",
        "    for i in vec:\n",
        "        if i >= threshold:\n",
        "            output.append(np.ceil(i))\n",
        "        else:\n",
        "            output.append(np.floor(i))\n",
        "    return np.array(output)\n",
        "\n",
        "def plot_confusion_matrix(cm,\n",
        "                      classes,\n",
        "                      normalized=False,\n",
        "                      title=None,\n",
        "                      cmap=plt.cm.Blues,\n",
        "                      size=(2,2)):\n",
        "    fig, ax = plt.subplots(figsize=size)\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)"
      ],
      "metadata": {
        "id": "-8fB3bUbzSs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (150, 150, 3)\n",
        "model_vgg19 = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "model_vgg19.trainable = False\n",
        "model_vgg19.summary()"
      ],
      "metadata": {
        "id": "Wm8UE2WyT1Yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add new classifier layers\n",
        "from keras.models import Model\n",
        "flat1 = model_vgg19.layers[-1].output\n",
        "flat1 = GlobalAveragePooling2D()(flat1)\n",
        "class1 = layers.Dense(64, activation='relu')(flat1)\n",
        "output = layers.Dense(1, activation='sigmoid')(class1)\n",
        "\n",
        "# define new model\n",
        "model = Model(inputs=model_vgg19.inputs, outputs=output)\n",
        "# summarize\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "LvdQLzQWUFVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  loss = \"binary_crossentropy\",\n",
        "  optimizer='adam',\n",
        "  metrics = [\"acc\"]\n",
        ")"
      ],
      "metadata": {
        "id": "DcSvvHO1Ub-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the model with train data and judging this training with validation data\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    batch_size=batch_size,\n",
        "    epochs = 5,\n",
        "    validation_data = validation_generator)"
      ],
      "metadata": {
        "id": "9WlZv68_UrxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train accuracy and validation accuracy vs epoch graph\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, label='Training acc')\n",
        "plt.plot(epochs, val_acc, label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, label='Training loss')\n",
        "plt.plot(epochs, val_loss, label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YYa-XP_WywXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions\n",
        "\n",
        "y_pred = model.predict(validation_generator)\n",
        "\n",
        "y_pred = _round(y_pred, 0.5)\n",
        "y_true = validation_generator.classes\n",
        "mcm = multilabel_confusion_matrix(y_true, y_pred)\n",
        "cmn = confusion_matrix(y_true, y_pred, normalize='true')\n",
        "print(cmn)"
      ],
      "metadata": {
        "id": "_mytmN70yyVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['dog', 'cat']\n",
        "plot_confusion_matrix(cmn,\n",
        "                      labels,\n",
        "                      normalized=True,\n",
        "                      title=\"Model Performance\",\n",
        "                      cmap=plt.cm.Blues,\n",
        "                      size=(2,2))"
      ],
      "metadata": {
        "id": "5j0PHh0BzALi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Natural Processing Language"
      ],
      "metadata": {
        "id": "C2bBRgwNG2PC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seq2Seq Model\n",
        "English to French Translator\n",
        "\n"
      ],
      "metadata": {
        "id": "JA2sJcOUG9QK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, CuDNNLSTM, Dense\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from numpy.random import seed\n",
        "seed(1)"
      ],
      "metadata": {
        "id": "L4t2uadBiW4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create new dir for dataset\n",
        "! mkdir /content/kaggleDataset/frenchenglish-bilingual-pairs\n",
        "\n",
        "# set Directory as current directory\n",
        "%cd /content/kaggleDataset/frenchenglish-bilingual-pairs"
      ],
      "metadata": {
        "id": "IgrokrZoin0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download the dataset\n",
        "!kaggle datasets download -d jannesklaas/frenchenglish-bilingual-pairs"
      ],
      "metadata": {
        "id": "59e8nhitin0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete path to storage location of the .zip file of data\n",
        "zip_path = '/content/kaggleDataset/frenchenglish-bilingual-pairs/frenchenglish-bilingual-pairs.zip'\n",
        "# Check current directory (be sure you're in the directory where Colab operates: '/content')\n",
        "os.getcwd()\n",
        "# Copy the .zip file into the present directory\n",
        "!cp '{zip_path}' .\n",
        "# Unzip quietly\n",
        "!unzip -q 'frenchenglish-bilingual-pairs.zip'\n",
        "# View the unzipped contents in the virtual machine\n",
        "os.listdir()"
      ],
      "metadata": {
        "id": "EMEi9pgkin0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 10000  # Number of samples to train on.\n",
        "\n",
        "# Path to the data txt file on disk.\n",
        "data_path = '/content/kaggleDataset/frenchenglish-bilingual-pairs/fra-eng/fra.txt'"
      ],
      "metadata": {
        "id": "klWOKtP-in0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read in the datafile\n",
        "df = pd.read_csv(data_path,delimiter='\\t', header=None)\n",
        "df = df.rename(columns={0: 'English', 1: 'French'})\n",
        "df"
      ],
      "metadata": {
        "id": "LaySHbqUjcrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "rXABF1NgkA4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vectorizing the data"
      ],
      "metadata": {
        "id": "5d1GRtsTkZiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "# Loop over lines\n",
        "lines = open(data_path).read().split('\\n')\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    # Input and target are split by tabs\n",
        "    # English TAB French\n",
        "    input_text, target_text = line.split('\\t')\n",
        "\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "\n",
        "    # Create a set of all unique characters in the input\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "\n",
        "    # Create a set of all unique output characters\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)"
      ],
      "metadata": {
        "id": "qxIrh-mvkfOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we achieve the same order in our input chars (sorted based on ASCII)\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "\n",
        "num_encoder_tokens = len(input_characters) # aka size of the english alphabet + numbers, signs, etc.\n",
        "num_decoder_tokens = len(target_characters) # aka size of the french alphabet + numbers, signs, etc.\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)"
      ],
      "metadata": {
        "id": "Ijsh91HrlCQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create character tokenizer\n",
        "# The index maps a character to a number\n",
        "input_token_index = {char: i for i, char in enumerate(input_characters)}\n",
        "target_token_index = {char: i for i, char in enumerate(target_characters)}"
      ],
      "metadata": {
        "id": "QSuxkJJZlhGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_token_index"
      ],
      "metadata": {
        "id": "lUxbQRhEoDXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo character tokenization\n",
        "for c in 'the cat sits on the mat':\n",
        "    print(input_token_index[c], end = ' ')\n",
        "    print(c)"
      ],
      "metadata": {
        "id": "9p1N_oWUlr0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get longest sequences length\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)"
      ],
      "metadata": {
        "id": "7aTMSJ3umGCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder_input_data is a 3D array of shape (num_pairs, max_english_sentence_length, num_english_characters)\n",
        "# containing a one-hot vectorization of the English sentences.\n",
        "\n",
        "encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens),dtype='float32')\n",
        "\n",
        "# decoder_input_data is a 3D array of shape (num_pairs, max_french_sentence_length, num_french_characters)\n",
        "# containg a one-hot vectorization of the French sentences.\n",
        "\n",
        "decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens),dtype='float32')\n",
        "\n",
        "# decoder_target_data is the same as decoder_input_data but offset by one timestep.\n",
        "# decoder_target_data[:, t, :] will be the same as decoder_input_data[:, t + 1, :]\n",
        "\n",
        "decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens),dtype='float32')"
      ],
      "metadata": {
        "id": "KGMZrE3imJ9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop over input texts\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "\n",
        "    # Loop over each char in an input text\n",
        "    for t, char in enumerate(input_text):\n",
        "        # Create one hot encoding by setting the index to 1\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "\n",
        "    # Loop over each char in the output text\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1."
      ],
      "metadata": {
        "id": "tcdzYTEMmlCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an input sequence and process it.\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens), name = 'encoder_inputs')\n",
        "\n",
        "# The return_state contructor argument, configuring a RNN layer to return a list\n",
        "# where the first entry is the outputs and the next entries are the internal RNN states.\n",
        "# This is used to recover the states of the encoder.\n",
        "encoder = CuDNNLSTM(latent_dim, return_state=True, name = 'encoder')\n",
        "\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens), name = 'decoder_inputs')\n",
        "\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = CuDNNLSTM(latent_dim, return_sequences=True, return_state=True, name = 'decoder_lstm')\n",
        "\n",
        "# The inital_state call argument, specifying the initial state(s) of a RNN.\n",
        "# This is used to pass the encoder states to the decoder as initial states.\n",
        "# Basically making the first memory of the decoder the encoded semantics\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name = 'decoder_dense')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "metadata": {
        "id": "Y6_wcQb4oKXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "metadata": {
        "id": "rQpooEJdoMKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "fngBe23Locv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run training\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n",
        "history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data,batch_size=batch_size,epochs=epochs,validation_split=0.2)"
      ],
      "metadata": {
        "id": "SqbAIpwZolb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,7))\n",
        "a, = plt.plot(history.history['loss'],label='Training Loss')\n",
        "b, = plt.plot(history.history['val_loss'],label='Validation Loss')\n",
        "plt.legend(handles=[a,b])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EdI1WGOKp_-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define encoder model\n",
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "metadata": {
        "id": "ba5Zhmpuq2fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define decoder model\n",
        "\n",
        "# Inputs from the encoder\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "\n",
        "# Create a combined memory to input into the decoder\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "\n",
        "# Predict next char\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "metadata": {
        "id": "CWRSJrrtrGSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The model takes in the encoder memory plus it's own memory as an input and spits out\n",
        "# a prediction plus its own memory to be used for the next char\n",
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
      ],
      "metadata": {
        "id": "AIiZFyLDrJyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = {i: char for char, i in input_token_index.items()}\n",
        "reverse_target_char_index = {i: char for char, i in target_token_index.items()}"
      ],
      "metadata": {
        "id": "WNmaCprRr0fT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    # Loop untill we recieve a stop sign\n",
        "    while not stop_condition:\n",
        "        # Get output and internal states of the decoder\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Get the predicted token (the token with the highest score)\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        # Get the character belonging to the token\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        # Append char to output\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "fN2ExH1VrNxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_text = 'Thanks'\n",
        "placeholder = np.zeros((1,len(my_text)+10,num_encoder_tokens))"
      ],
      "metadata": {
        "id": "4B6CZSlQrTG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, char in enumerate(my_text):\n",
        "    print(i,char, input_token_index[char])\n",
        "    placeholder[0,i,input_token_index[char]] = 1"
      ],
      "metadata": {
        "id": "5E32CxoLsuqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decode_sequence(placeholder)"
      ],
      "metadata": {
        "id": "Mu-Z48uZsv8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Learning"
      ],
      "metadata": {
        "id": "0LalKsbD9o9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "F-hjW3JyZ7-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "dqa7n9lkaBIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# explore the dataset\n",
        "print(\"Number of training examples:\", x_train.shape[0])\n",
        "print(\"Number of test examples:\", x_test.shape[0])"
      ],
      "metadata": {
        "id": "_xCFavmwaFb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the first training example\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(0,5):\n",
        "  plt.imshow(x_train[i], cmap='gray')\n",
        "  plt.title('Ground Truth : {}'.format(y_train[i]))\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "iL0oGbAIaHiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape and normalize the input data\n",
        "x_train = x_train.reshape(-1, 784) / 255.0\n",
        "x_test = x_test.reshape(-1, 784) / 255.0"
      ],
      "metadata": {
        "id": "qH8z3euoaqw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the labels to one-hot encoded vectors\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
      ],
      "metadata": {
        "id": "9n_RuCHVboct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the deep learning model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation='relu', input_shape=(784,)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "T6jz4R-Zbstd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "OX7QiUuGbzD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "lvjY4QCjcQGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "oJLYk5g8czCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "8SSG7Mvtc1bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use history object to plot the training and validation accuracy for each epoch\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# use history object to plot the training and validation loss for each epoch\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8b648L20ectO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yKN_0C6EhHiN",
        "6Jo6r-jaGkfc",
        "DdYPXjAeGoxa",
        "0LalKsbD9o9u"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}