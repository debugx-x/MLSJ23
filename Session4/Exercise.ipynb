{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvp_LYvFlaJ2"
      },
      "source": [
        "\n",
        "\n",
        "# ML Study Jam Exercise 4 - HUMAN EMOTION DETECTION"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install necessary Libraries"
      ],
      "metadata": {
        "id": "ePzWEkf6PhZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install numpy opencv-python tensorflow pandas"
      ],
      "metadata": {
        "id": "Dvfnb59NPtUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Kaggle Library"
      ],
      "metadata": {
        "id": "yKN_0C6EhHiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install kaggle libary\n",
        "%pip install -q kaggle"
      ],
      "metadata": {
        "id": "0rXctsWkic3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# upload Kaggle API Credentials\n",
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "3JJPS7enic3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add kaggle API credentials to root\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "DsVM5RYjic3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new folder to save dataset\n",
        "! mkdir ./kaggleDataset\n",
        "\n",
        "# set Directory as current directory\n",
        "%cd ./kaggleDataset"
      ],
      "metadata": {
        "id": "hBcdw1gkic3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list kaggle datasets\n",
        "! kaggle datasets list"
      ],
      "metadata": {
        "id": "jfq9hAhNic3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dataset"
      ],
      "metadata": {
        "id": "mazOSBaAQiZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# create new dir for dataset\n",
        "! mkdir ./fer2013\n",
        "\n",
        "# set Directory as current directory\n",
        "%cd ./fer2013"
      ],
      "metadata": {
        "id": "z-2FL1h4qLIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download the dataset\n",
        "!kaggle datasets download -d msambare/fer2013"
      ],
      "metadata": {
        "id": "7fQPRSWai8bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete path to storage location of the .zip file of data\n",
        "zip_path = '/content/kaggleDataset/fer2013/fer2013.zip'\n",
        "# Check current directory (be sure you're in the directory where Colab operates: '/content')\n",
        "os.getcwd()\n",
        "# Copy the .zip file into the present directory\n",
        "!cp '{zip_path}' .\n",
        "# Unzip quietly\n",
        "!unzip -q 'fer2013.zip'\n",
        "# View the unzipped contents in the virtual machine\n",
        "os.listdir()"
      ],
      "metadata": {
        "id": "mLQggAmkjFw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Analysis"
      ],
      "metadata": {
        "id": "M88qAgRiSxbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up file paths\n",
        "TRAIN_PATH='/content/kaggleDataset/fer2013/train'\n",
        "TEST_PATH='/content/kaggleDataset/fer2013/test'"
      ],
      "metadata": {
        "id": "7pR7Q21SqpDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_names = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
        "\n",
        "category_info = []\n",
        "\n",
        "for category in category_names:\n",
        "    path = os.path.join(TRAIN_PATH, category)\n",
        "    class_num = category_names.index(category)\n",
        "    count = 1\n",
        "    for img in os.listdir(path):\n",
        "      count +=1\n",
        "    category_info.append({\n",
        "        'label': category,\n",
        "        'Count': count\n",
        "    })\n",
        "    print(category + \" : \" + str(count))"
      ],
      "metadata": {
        "id": "2bnjCCvxUKrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot histogram for labels\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "labels = [item['label'] for item in category_info]\n",
        "counts = [item['Count'] for item in category_info]\n",
        "\n",
        "plt.bar(labels, counts)\n",
        "plt.xlabel('Categories')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Histogram of Category Counts')\n",
        "plt.xticks(rotation=45)  # Rotate the x-axis labels for better readability\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jsYeXM6LVOCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import load_img\n",
        "\n",
        "plt.figure(figsize=(14,22))\n",
        "i = 1\n",
        "for expression in os.listdir(TRAIN_PATH):\n",
        "    img = load_img((TRAIN_PATH + '/' + expression +'/'+ os.listdir(TRAIN_PATH + '/' + expression)[6]))\n",
        "    plt.subplot(1,7,i)\n",
        "    plt.imshow(img)\n",
        "    plt.title(expression)\n",
        "    plt.axis('off')\n",
        "    i += 1\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RIsTZDKyZ8r5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_array = cv2.imread('train/happy/Training_39155692.jpg')\n",
        "img_array.shape"
      ],
      "metadata": {
        "id": "aQYOS_shS1Pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img_array)"
      ],
      "metadata": {
        "id": "-QBXGEehTSjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_array = cv2.resize(img_array, (224, 224))\n",
        "plt.imshow(cv2.cvtColor(new_array, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FzUernTATjps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "ruO0l2EnSKAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "glubeNZ9Tw0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Data Augmentation\n",
        "--------------------------\n",
        "rotation_range = rotates the image with the amount of degrees we provide\n",
        "width_shift_range = shifts the image randomly to the right or left along the width of the image\n",
        "height_shift range = shifts image randomly to up or below along the height of the image\n",
        "horizontal_flip = flips the image horizontally\n",
        "rescale = to scale down the pizel values in our image between 0 and 1\n",
        "zoom_range = applies random zoom to our object\n",
        "validation_split = reserves some images to be used for validation purpose\n",
        "\"\"\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(width_shift_range = 0.1,\n",
        "                                  height_shift_range = 0.1,\n",
        "                                  horizontal_flip = True,\n",
        "                                  rescale = 1./255,\n",
        "                                  validation_split = 0.2\n",
        "                                  )\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                         validation_split = 0.2)"
      ],
      "metadata": {
        "id": "otz8UmnYSOsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Applying data augmentation to the images as we read\n",
        "them from their respective directories\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "img_size = 48 #original size of the image\n",
        "\n",
        "#%% MODEL HYPERPARAMETER BATCH_SIZE [32 - 256] (Multiples of 2) %%\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(directory = TRAIN_PATH,\n",
        "                                                    target_size = (img_size,img_size),\n",
        "                                                    batch_size = batch_size,\n",
        "                                                    color_mode = \"grayscale\", # rgb for transfer learning\n",
        "                                                    class_mode = \"categorical\",\n",
        "                                                    subset = \"training\"\n",
        "                                                   )\n",
        "validation_generator = validation_datagen.flow_from_directory( directory = TEST_PATH,\n",
        "                                                              target_size = (img_size,img_size),\n",
        "                                                              batch_size = batch_size,\n",
        "                                                              color_mode = \"grayscale\", # rgb for transfer learning\n",
        "                                                              class_mode = \"categorical\",\n",
        "                                                              subset = \"validation\"\n",
        "                                                             )"
      ],
      "metadata": {
        "id": "ri5q8syJYIJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Construction"
      ],
      "metadata": {
        "id": "7mu0RRJqSPKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten,Dense,Dropout,BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras import regularizers\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "m96OYQzXbip6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build A Model"
      ],
      "metadata": {
        "id": "k18mPjgZY6ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "RESNET Modeling\n",
        "\n",
        "def identity_block(x, filter):\n",
        "    # copy tensor to variable called x_skip\n",
        "    x_skip = x\n",
        "    # Layer 1\n",
        "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    # Layer 2\n",
        "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
        "    # Add Residue\n",
        "    x = tf.keras.layers.Add()([x, x_skip])\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def convolutional_block(x, filter):\n",
        "    # copy tensor to variable called x_skip\n",
        "    x_skip = x\n",
        "    # Layer 1\n",
        "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    # Layer 2\n",
        "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
        "    # Processing Residue with conv(1,1)\n",
        "    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n",
        "    # Add Residue\n",
        "    x = tf.keras.layers.Add()([x, x_skip])\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "shape = (48, 48, 1)\n",
        "classes = 7\n",
        "\n",
        "# Step 1 (Setup Input Layer)\n",
        "x_input = tf.keras.layers.Input(shape)\n",
        "x = tf.keras.layers.ZeroPadding2D((3, 3))(x_input)\n",
        "\n",
        "# Step 2 (Initial Conv layer along with maxPool)\n",
        "x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Activation('relu')(x)\n",
        "x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
        "\n",
        "# Define size of sub-blocks and initial filter size\n",
        "block_layers = [3, 4, 6, 3]\n",
        "filter_size = 64\n",
        "\n",
        "# Step 3 Add the Resnet Blocks\n",
        "for i in range(4):\n",
        "    if i == 0:\n",
        "        # For sub-block 1 Residual/Convolutional block not needed\n",
        "        for j in range(block_layers[i]):\n",
        "            x = identity_block(x, filter_size)\n",
        "    else:\n",
        "        # One Residual/Convolutional Block followed by Identity blocks\n",
        "        # The filter size will go on increasing by a factor of 2\n",
        "        filter_size = filter_size*2\n",
        "        x = convolutional_block(x, filter_size)\n",
        "        for j in range(block_layers[i] - 1):\n",
        "            x = identity_block(x, filter_size)\n",
        "\n",
        "# Step 4 End Dense Network\n",
        "x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
        "x = tf.keras.layers.Dense(classes, activation = 'softmax')(x)\n",
        "\n",
        "model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet34\")\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "mv6doATuzKkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Modeling\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 64,kernel_size = (3,3),padding = 'same',activation = 'relu',input_shape=(img_size,img_size,1)))\n",
        "model.add(MaxPooling2D(pool_size = 2,strides = 2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters = 128,kernel_size = (3,3),padding = 'same',activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = 2,strides = 2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters = 128,kernel_size = (3,3),padding = 'same',activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = 2,strides = 2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters = 256,kernel_size = (3,3),padding = 'same',activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = 2,strides = 2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units = 128,activation = 'relu',kernel_initializer='he_normal'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(units = 64,activation = 'relu',kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(units = 32,activation = 'relu',kernel_initializer='he_normal'))\n",
        "model.add(Dense(7,activation = 'softmax'))\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aIxx0B1HSSIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Convolutional layer 1  -- > input_shape=(48, 48, 1) for grayscale input_shape=(48, 48, 3) for rgb\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(48, 48, 1)))  # Input shape: (48, 48, 1), Output shape: (48, 48, 32)\n",
        "\n",
        "# Convolutional layer 2\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))  # Output shape: (48, 48, 64)\n",
        "\n",
        "# Batch Normalization\n",
        "model.add(BatchNormalization())  # Output shape: (48, 48, 64)\n",
        "\n",
        "# Max Pooling\n",
        "model.add(MaxPooling2D(2, 2))  # Input shape: (48, 48, 64), Output shape: (24, 24, 64)\n",
        "\n",
        "# Dropout\n",
        "model.add(Dropout(0.25))  # Input shape: (24, 24, 64), Output shape: (24, 24, 64)\n",
        "\n",
        "# Convolutional layer 3 with L2 regularization\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)))  # Input shape: (24, 24, 64), Output shape: (24, 24, 128)\n",
        "\n",
        "# Convolutional layer 4 with L2 regularization\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))  # Input shape: (24, 24, 128), Output shape: (22, 22, 256)\n",
        "\n",
        "# Batch Normalization\n",
        "model.add(BatchNormalization())  # Output shape: (22, 22, 256)\n",
        "\n",
        "# Max Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))  # Input shape: (22, 22, 256), Output shape: (11, 11, 256)\n",
        "\n",
        "# Dropout\n",
        "model.add(Dropout(0.25))  # Input shape: (11, 11, 256), Output shape: (11, 11, 256)\n",
        "\n",
        "# Flatten\n",
        "model.add(Flatten())  # Input shape: (11, 11, 256), Output shape: 30976\n",
        "\n",
        "# Fully Connected layer 1\n",
        "model.add(Dense(1024, activation='relu'))  # Input shape: 30976, Output shape: 1024\n",
        "\n",
        "# Dropout\n",
        "model.add(Dropout(0.5))  # Input shape: 1024, Output shape: 1024\n",
        "\n",
        "# Fully Connected layer 2\n",
        "model.add(Dense(7, activation='softmax'))  # Input shape: 1024, Output shape: 7\n"
      ],
      "metadata": {
        "id": "nK07KVR7nhbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer Learning"
      ],
      "metadata": {
        "id": "6XLBRMSSY-cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_MobileNet = tf.keras.applications.MobileNetV2()\n",
        "base_input = model_MobileNet.layers[0].input\n",
        "base_output = model_MobileNet.layers[-2].output"
      ],
      "metadata": {
        "id": "1_657PPpYwRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_output = layers.Dense(128)(base_output)\n",
        "final_output = layers.Activation('relu')(final_output)\n",
        "final_output = layers.Dense(64)(final_output)\n",
        "final_output = layers.Activation('relu')(final_output)\n",
        "final_output = layers.Dense(7, activation='softmax')(final_output)"
      ],
      "metadata": {
        "id": "sulMGo7XbeHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Model(inputs = base_input, outputs = final_output)"
      ],
      "metadata": {
        "id": "xwqzHeClbgA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Summary"
      ],
      "metadata": {
        "id": "eroS6dpqbW-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%% MODEL HYPERPARAMETER LEARNING RATE [0.1 - 0.001 - 0.0001] %%\n",
        "#%% MODEL HYPERPARAMETER WEIGHT DECAY [0.0001 - 0.001] (Multiples of 2) %%\n",
        "\n",
        "model.compile(\n",
        "    optimizer = Adam(learning_rate=0.0001, decay=1e-6),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "  )"
      ],
      "metadata": {
        "id": "nghOAKtscjMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "5pL7WAqqYk2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model\n",
        "\n",
        "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "JD8uOIEEa88k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "PqYQr1FUSUH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, ReduceLROnPlateau\n",
        "import datetime\n",
        "\n",
        "chk_path = 'model.h5'\n",
        "log_dir = \"checkpoint/logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=chk_path,\n",
        "                             save_best_only=True,\n",
        "                             verbose=1,\n",
        "                             mode='min',\n",
        "                             moniter='val_loss')\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
        "                              factor=0.2,\n",
        "                              patience=6,\n",
        "                              verbose=1,\n",
        "                              min_delta=0.0001)\n",
        "\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "csv_logger = CSVLogger('training.log')\n",
        "\n",
        "callbacks = [checkpoint, reduce_lr, csv_logger]"
      ],
      "metadata": {
        "id": "yADFsaXTSWxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = train_generator.n // train_generator.batch_size\n",
        "validation_steps = validation_generator.n // validation_generator.batch_size\n",
        "\n",
        "hist = model.fit(x=train_generator,\n",
        "                 validation_data=validation_generator,\n",
        "                 epochs=60, # 30 for TL\n",
        "                 callbacks=callbacks,\n",
        "                 steps_per_epoch=steps_per_epoch,\n",
        "                 validation_steps=validation_steps)"
      ],
      "metadata": {
        "id": "cdEkTq8_dMK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "5g9LYBD6d3an"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14,5))\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oHG3wl1kd6Kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, train_accu = model.evaluate(train_generator)\n",
        "test_loss, test_accu = model.evaluate(validation_generator)\n",
        "print(\"final train accuracy = {:.2f} , validation accuracy = {:.2f}\".format(train_accu*100, test_accu*100))"
      ],
      "metadata": {
        "id": "z3Z5m26Cd_gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "y_pred = model.predict(train_generator)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "class_labels = validation_generator.class_indices\n",
        "class_labels = {v:k for k,v in class_labels.items()}\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "cm_train = confusion_matrix(train_generator.classes, y_pred)\n",
        "print('Confusion Matrix')\n",
        "print(cm_train)\n",
        "print('Classification Report')\n",
        "target_names = list(class_labels.values())\n",
        "print(classification_report(train_generator.classes, y_pred, target_names=target_names))\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(cm_train, interpolation='nearest')\n",
        "plt.colorbar()\n",
        "tick_mark = np.arange(len(target_names))\n",
        "_ = plt.xticks(tick_mark, target_names, rotation=90)\n",
        "_ = plt.yticks(tick_mark, target_names)"
      ],
      "metadata": {
        "id": "8Zoc3VRioRyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Testing"
      ],
      "metadata": {
        "id": "00cvFa4AnEnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import load_img\n",
        "img = load_img(TEST_PATH + \"img path here \", target_size = (48,48), color_mode = \"grayscale\")\n",
        "img = np.array(img)\n",
        "plt.imshow(img)\n",
        "print(img.shape)"
      ],
      "metadata": {
        "id": "5r9f5RzvnQ8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_names = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']"
      ],
      "metadata": {
        "id": "hMDpzAjlnyyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import img_to_array\n",
        "test_image = img_to_array(img)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "prediction = model.predict(test_image)\n",
        "prediction[0]"
      ],
      "metadata": {
        "id": "0rcG1hE2njFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = np.argmax(prediction[0])\n",
        "print('predicted Label for that image is: {}'.format(category_names[res]))"
      ],
      "metadata": {
        "id": "yAii52Janyby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment"
      ],
      "metadata": {
        "id": "QUN0QU3pSXC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model_seq_optimal.h5')"
      ],
      "metadata": {
        "id": "yYoIPx9XScr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('model_weights.h5')"
      ],
      "metadata": {
        "id": "Kpb4v7-QegE1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ePzWEkf6PhZW",
        "yKN_0C6EhHiN",
        "mazOSBaAQiZ9",
        "M88qAgRiSxbs",
        "ruO0l2EnSKAb",
        "7mu0RRJqSPKl",
        "k18mPjgZY6ho",
        "eroS6dpqbW-R",
        "PqYQr1FUSUH1",
        "5g9LYBD6d3an",
        "00cvFa4AnEnT",
        "QUN0QU3pSXC9"
      ],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}